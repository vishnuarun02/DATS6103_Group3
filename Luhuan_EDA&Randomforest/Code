import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
from scipy.stats import chi2_contingency
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


students = pd.read_csv('C:/Users/luhua/Desktop/DS03/final pre/data.csv', delimiter=';')
df = students.copy()

# EDA about  Parents qualificationParents occupationDisplaced, Educational special needs, Debtor, Tuition fees up to
# date, Scholarship holder, International
# Parents qualification
# count 'Mother's qualification'  'Father's qualification'
# Frequency distribution of parenthood
plt.figure(figsize=(10, 6))
students["Mother's qualification"].value_counts().plot(kind='bar', color='skyblue')
plt.xlabel("Mother's Qualification")
plt.ylabel('Count')
plt.title("Distribution of Mother's Qualification")
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(10, 6))
students["Father's qualification"].value_counts().plot(kind='bar', color='lightgreen')
plt.xlabel("Father's Qualification")
plt.ylabel('Count')
plt.title("Distribution of Father's Qualification")
plt.xticks(rotation=45)
plt.show()

# Quantitative distribution of parentsâ€™ occupations
plt.figure(figsize=(10, 6))
students["Mother's occupation"].value_counts().plot(kind='bar', color='skyblue')
plt.xlabel("Mother's Occupation")
plt.ylabel('Count')
plt.title("Distribution of Mother's Occupation")
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(10, 6))
students["Father's occupation"].value_counts().plot(kind='bar', color='lightgreen')
plt.xlabel("Father's Occupation")
plt.ylabel('Count')
plt.title("Distribution of Father's Occupation")
plt.xticks(rotation=45)
plt.show()

# Proportional display of binary variable columns
binary_cols = ['Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', 'Scholarship holder', 'International']

plt.figure(figsize=(15, 10))
for i, col in enumerate(binary_cols, 1):
    plt.subplot(2, 3, i)
    counts = students[col].value_counts()
    plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=140)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()


mapping_dict = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}

students['Target'] = students['Target'].replace(mapping_dict)
correlation_matrix = students.corr()
print(correlation_matrix)

# Mother's qualification  Father's qualification
contingency_table = pd.crosstab(students["Mother's qualification"], students["Father's qualification"])
chi2, p, dof, expected = chi2_contingency(contingency_table)
print(f"Chi-Square Test Statistic: {chi2}")
print(f"P-value: {p}")

# Educational special needs
for col in ['Debtor', 'Tuition fees up to date', 'Scholarship holder', 'International']:
    contingency_table = pd.crosstab(students['Educational special needs'], students[col])
    chi2, p, dof, expected = chi2_contingency(contingency_table)
    print(f"Chi-Square Test Statistic for Educational special needs vs {col}: {chi2}")
    print(f"P-value: {p}")
# The chi-square test statistic between Educational special needs and Debtor is 0.0, with a p-value of 1.0. This may
# indicate that there is no obvious correlation between them. The chi-square test statistic between Educational
# special needs and Tuition fees up to date is 0.475, with a p-value of 0.491. A higher p value indicates that the
# correlation between the two is weak and not significant enough. The chi-square test statistic between Educational
# special needs and Scholarship holder is 1.559, with a p-value of 0.212. A higher p value indicates that the
# correlation between the two is not significant enough. The chi-square test statistic between Educational special
# needs and International is 0.0, with a p-value of 1.0. There may be no obvious connection between the two.

# random forest

# List of columns to keep
cols = ['Application mode', 'Course', 'Previous qualification', "Mother's qualification", 'Tuition fees up to date',
        "Mother's occupation", 'Gender', 'Scholarship holder', 'Age at enrollment', 'Curricular units 1st sem ('
                                                                                    'approved)',
        'Curricular units 2nd sem (approved)', 'Target']

# Keep only relevant columns
df = df[cols]

# Remove 'Enrolled' students from the dataset
df = df[df['Target'] != 'Enrolled']

# Convert 'Target' column into numerical data type
df = df.replace({'Target': {'Dropout': 0, 'Graduate': 1}})
df['Target'] = df['Target'].astype('int32')

# Perform one-hot encoding for categorical columns
df = pd.get_dummies(df, drop_first=True)

# Define predictor and target variables
y = df['Target']
X = df.drop('Target', axis=1)

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

# Set up Random Forest classifier and GridSearchCV
rf = RandomForestClassifier(random_state=0)
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
}

grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print("Best Hyperparameters:", grid_search.best_params_)
rf_accuracy = grid_search.best_estimator_.score(X_test, y_test)
print("Test Accuracy:", rf_accuracy)

# Fit the model with best parameters from GridSearchCV
rf = RandomForestClassifier(**grid_search.best_params_, random_state=0)
rf.fit(X_train, y_train)

# Make predictions on the test set
y_preds = rf.predict(X_test)

# Evaluate model performance
accuracy = accuracy_score(y_test, y_preds)
precision = precision_score(y_test, y_preds)
recall = recall_score(y_test, y_preds)
f1 = f1_score(y_test, y_preds)

print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1 Score: {f1:.3f}")

# Plot confusion matrix
cm = confusion_matrix(y_test, y_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Dropout', 'Graduate'])
disp.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

# Calculate predicted probabilities and plot ROC curve
y_preds_prob_rf = rf.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_preds_prob_rf)
auc = roc_auc_score(y_test, y_preds_prob_rf)

plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title(f'ROC Curve (AUC = {auc:.2f})')
plt.show()
